{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": ""
    }
   },
   "source": [
    "## D7041E - Mini project: Human Real-time Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Group: Laura Bermejo, Lina Borg, Julie Labb√©"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### References and sources\n",
    "For the training of our model, we got inspired by this video: https://www.youtube.com/watch?v=V4Kkrz__hvo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Requirements\n",
    "The required libraries are super-gradient (for model), roboflow (for dataset) and supervision (for bounding boxes)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pip install -q super-gradients <br>\n",
    "pip install -q roboflow <br>\n",
    "pip install -q supervision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "##### Code to download the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"DNm47rTel6WBxKZqAd9T\")\n",
    "project = rf.workspace(\"capricon\").project(\"human-detection-q0nit\")\n",
    "dataset = project.version(2).download(\"yolov5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### class Config Class definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from typing import List, Dict\n",
    "\n",
    "class config:\n",
    "  #Project paths\n",
    "  DATA_DIR: str = \"Human-Detection-2\"\n",
    "  CHECKPOINT_DIR: str = \"/checkpoints\"\n",
    "  EXPERIMENT_NAME: str = \"Project\"\n",
    "\n",
    "  #Datasets\n",
    "  TRAIN_IMAGES_DIR: str =\"train/images\"\n",
    "  TRAIN_LABELS_DIR: str = \"train/labels\"\n",
    "  VAL_IMAGES_DIR: str = \"valid/images\"\n",
    "  VAL_LABELS_DIR: str = \"valid/labels\"\n",
    "  TEST_IMAGES_DIR: str = \"test/images\"\n",
    "  TEST_LABELS_DIR: str = \"test/labels\"\n",
    "\n",
    "  #Classes\n",
    "  CLASSES: List[str] = [\"human\", \"vehicle\"]\n",
    "  NUM_CLASSES: int = 2\n",
    "\n",
    "  #Model 1\n",
    "  # DEFINE HYPERPARAMETERS, YOU WILL HAVE TO CHANGE IT\n",
    "  DATALOADER_PARAMS: Dict = {\n",
    "      'batch_size':16,\n",
    "      'num_workers':0\n",
    "  }\n",
    "  # THIS IS ALREADY SET, CHANGE ONLY DATALOADER PARAMS\n",
    "  MODEL_NAME: str = 'yolo_nas_l'\n",
    "  PRETRAINED_WEIGHTS: str ='coco'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Dataloaders initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "from typing import List, Dict\n",
    "from super_gradients.training import models\n",
    "from super_gradients.training import Trainer\n",
    "from super_gradients.training.dataloaders.dataloaders import coco_detection_yolo_format_train\n",
    "from super_gradients.training.dataloaders.dataloaders import coco_detection_yolo_format_val\n",
    "from super_gradients.training.losses import PPYoloELoss\n",
    "from super_gradients.training.metrics import DetectionMetrics_050\n",
    "from super_gradients.training.models.detection_models.pp_yolo_e import PPYoloEPostPredictionCallback\n",
    "from typing import List, Dict\n",
    "from super_gradients.training.dataloaders.dataloaders import coco_detection_yolo_format_train\n",
    "from super_gradients.training.dataloaders.dataloaders import coco_detection_yolo_format_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_data = coco_detection_yolo_format_train(\n",
    "    dataset_params={\n",
    "        'data_dir': config.DATA_DIR,\n",
    "        'images_dir': config.TRAIN_IMAGES_DIR,\n",
    "        'labels_dir': config.TRAIN_LABELS_DIR,\n",
    "        'classes': config.CLASSES\n",
    "    },\n",
    "    dataloader_params=config.DATALOADER_PARAMS\n",
    ")\n",
    "\n",
    "test_data = coco_detection_yolo_format_val(\n",
    "    dataset_params={\n",
    "        'data_dir': config.DATA_DIR,\n",
    "        'images_dir': config.TRAIN_IMAGES_DIR,\n",
    "        'labels_dir': config.TRAIN_LABELS_DIR,\n",
    "        'classes': config.CLASSES\n",
    "    },\n",
    "    dataloader_params=config.DATALOADER_PARAMS\n",
    ")\n",
    "\n",
    "val_data = coco_detection_yolo_format_val(\n",
    "    dataset_params={\n",
    "        'data_dir': config.DATA_DIR,\n",
    "        'images_dir': config.TRAIN_IMAGES_DIR,\n",
    "        'labels_dir': config.TRAIN_LABELS_DIR,\n",
    "        'classes': config.CLASSES\n",
    "    },\n",
    "    dataloader_params=config.DATALOADER_PARAMS\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def read_data(path):\n",
    "    dataset = []\n",
    "    for filename in os.listdir(path):\n",
    "        file_path = os.path.join(path, filename)\n",
    "        if \"images\" in path:\n",
    "            file = cv2.imread(file_path)\n",
    "        if \"labels\" in path:\n",
    "                with open(file_path, 'r') as file:\n",
    "                    lines = file.readlines()\n",
    "                    file = []\n",
    "                    for line in lines:\n",
    "                        values = line.strip().split()\n",
    "                        class_label = int(values[0])\n",
    "                        bbox_coords = [float(val) for val in values[1:]]\n",
    "                        annotation = [class_label] + bbox_coords\n",
    "                        file.append(annotation)\n",
    "                    file = np.array(file)\n",
    "        dataset.append(file)\n",
    "    return np.array(dataset)\n",
    "\n",
    "def write_data(dataset, path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "    for i, file in enumerate(dataset):\n",
    "        if \"images\" in path:\n",
    "            filename = f\"{i}.jpg\"\n",
    "            output_path = os.path.join(path, filename)\n",
    "            cv2.imwrite(output_path, file)\n",
    "        if \"labels\" in path:\n",
    "            for i, annotation in enumerate(dataset):\n",
    "                filename = f\"{i}.txt\"\n",
    "                output_path = os.path.join(path, filename)\n",
    "\n",
    "                with open(output_path, 'w') as file:\n",
    "                    for value in annotation:\n",
    "                        line = ' '.join(map(str, value))\n",
    "                        file.write(line)\n",
    "                        file.write('\\n') \n",
    "        \n",
    "\n",
    "def cross_validation(values, labels):\n",
    "    current_iteration = 0\n",
    "    best_accuracy = 0.0\n",
    "    num_folds = 3\n",
    "    kf = KFold(n_splits=num_folds) # TODO: change the seed here\n",
    "\n",
    "    for train_index, test_index in kf.split(values):\n",
    "        values_train, values_test = values[train_index], values[test_index]\n",
    "        labels_train, labels_test = labels[train_index], labels[test_index]\n",
    "\n",
    "        # In order to use the training function, we need to store the images and labels in respective folders\n",
    "        output_path = dataset.location + f\"/train_fold_{current_iteration}\"\n",
    "        write_data(values_train, output_path + \"/images\")\n",
    "        write_data(labels_train, output_path + \"/labels\")\n",
    "        current_iteration += 1\n",
    "        \n",
    "        #predicted_labels = predict(values_test, values_train, labels_train, k)\n",
    "        #accuracy = accuracy_score(labels_test, predicted_labels)\n",
    "        #total_accuracy += accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data in order to split it in folds\n",
    "path = dataset.location + \"/train\"\n",
    "loaded_dataset = read_data(path + \"/images\")\n",
    "loaded_labels = read_data(path + \"/labels\")\n",
    "cross_validation(loaded_dataset, loaded_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": ""
    }
   },
   "source": [
    "## D7041E - Mini project: Human Real-time Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group: Laura Bermejo, Lina Borg, Julie Labbé"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### References and sources\n",
    "For the training of our model, we got inspired by this video: https://www.youtube.com/watch?v=V4Kkrz__hvo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Requirements\n",
    "The required libraries are super-gradient (for model), roboflow (for dataset) and supervision (for bounding boxes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "roboflow 1.1.15 requires pyparsing==2.4.7, but you have pyparsing 2.4.5 which is incompatible.\n",
      "fuzzingbook 1.1 requires pyparsing==2.4.7, but you have pyparsing 2.4.5 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 23.3.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "super-gradients 3.5.0 requires pyparsing==2.4.5, but you have pyparsing 2.4.7 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 23.3.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 23.3.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q super-gradients\n",
    "%pip install -q roboflow\n",
    "%pip install -q supervision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Code to download the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in Human-Detection-2 to yolov5pytorch:: 100%|██████████| 32117/32117 [01:06<00:00, 481.56it/s] \n",
      "Extracting Dataset Version Zip to Human-Detection-2 in yolov5pytorch::   2%|▏         | 6/376 [00:00<00:06, 59.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Dataset Version Zip to Human-Detection-2 in yolov5pytorch:: 100%|██████████| 376/376 [00:02<00:00, 173.19it/s]\n"
     ]
    }
   ],
   "source": [
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"DNm47rTel6WBxKZqAd9T\")\n",
    "project = rf.workspace(\"capricon\").project(\"human-detection-q0nit\")\n",
    "dataset = project.version(2).download(\"yolov5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### class Config Class definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict\n",
    "\n",
    "class config:\n",
    "  #Project paths\n",
    "  DATA_DIR: str = \"Human-Detection-2\"\n",
    "  CHECKPOINT_DIR: str = \"/checkpoints\"\n",
    "  EXPERIMENT_NAME: str = \"Project\"\n",
    "\n",
    "  #Datasets\n",
    "  TRAIN_IMAGES_DIR: str =\"train/images\"\n",
    "  TRAIN_LABELS_DIR: str = \"train/labels\"\n",
    "  VAL_IMAGES_DIR: str = \"valid/images\"\n",
    "  VAL_LABELS_DIR: str = \"valid/labels\"\n",
    "  TEST_IMAGES_DIR: str = \"test/images\"\n",
    "  TEST_LABELS_DIR: str = \"test/labels\"\n",
    "\n",
    "  #Classes\n",
    "  CLASSES: List[str] = [\"human\", \"vehicle\"]\n",
    "  NUM_CLASSES: int = 2\n",
    "\n",
    "  #Model 1\n",
    "  # DEFINE HYPERPARAMETERS, YOU WILL HAVE TO CHANGE IT\n",
    "  DATALOADER_PARAMS: Dict = {\n",
    "      'batch_size':16,\n",
    "      'num_workers':0\n",
    "  }\n",
    "  # THIS IS ALREADY SET, CHANGE ONLY DATALOADER PARAMS\n",
    "  MODEL_NAME: str = 'yolo_nas_l'\n",
    "  PRETRAINED_WEIGHTS: str ='coco'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataloaders initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "from typing import List, Dict\n",
    "from super_gradients.training import models\n",
    "from super_gradients.training import Trainer\n",
    "from super_gradients.training.dataloaders.dataloaders import coco_detection_yolo_format_train\n",
    "from super_gradients.training.dataloaders.dataloaders import coco_detection_yolo_format_val\n",
    "from super_gradients.training.losses import PPYoloELoss\n",
    "from super_gradients.training.metrics import DetectionMetrics_050\n",
    "from super_gradients.training.models.detection_models.pp_yolo_e import PPYoloEPostPredictionCallback\n",
    "from typing import List, Dict\n",
    "from super_gradients.training.dataloaders.dataloaders import coco_detection_yolo_format_train\n",
    "from super_gradients.training.dataloaders.dataloaders import coco_detection_yolo_format_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-01-06 21:47:15] INFO - detection_dataset.py - Dataset Initialization in progress. `cache_annotations=True` causes the process to take longer due to full dataset indexing.\n",
      "Indexing dataset annotations: 100%|██████████| 159/159 [00:00<00:00, 681.92it/s]\n",
      "[2024-01-06 21:47:15] INFO - detection_dataset.py - Dataset Initialization in progress. `cache_annotations=True` causes the process to take longer due to full dataset indexing.\n",
      "Indexing dataset annotations: 100%|██████████| 159/159 [00:00<00:00, 515.85it/s]\n",
      "[2024-01-06 21:47:16] INFO - detection_dataset.py - Dataset Initialization in progress. `cache_annotations=True` causes the process to take longer due to full dataset indexing.\n",
      "Indexing dataset annotations:  43%|████▎     | 69/159 [00:00<00:00, 685.50it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Indexing dataset annotations: 100%|██████████| 159/159 [00:00<00:00, 503.70it/s]\n"
     ]
    }
   ],
   "source": [
    "train_data = coco_detection_yolo_format_train(\n",
    "    dataset_params={\n",
    "        'data_dir': config.DATA_DIR,\n",
    "        'images_dir': config.TRAIN_IMAGES_DIR,\n",
    "        'labels_dir': config.TRAIN_LABELS_DIR,\n",
    "        'classes': config.CLASSES\n",
    "    },\n",
    "    dataloader_params=config.DATALOADER_PARAMS\n",
    ")\n",
    "\n",
    "test_data = coco_detection_yolo_format_val(\n",
    "    dataset_params={\n",
    "        'data_dir': config.DATA_DIR,\n",
    "        'images_dir': config.TRAIN_IMAGES_DIR,\n",
    "        'labels_dir': config.TRAIN_LABELS_DIR,\n",
    "        'classes': config.CLASSES\n",
    "    },\n",
    "    dataloader_params=config.DATALOADER_PARAMS\n",
    ")\n",
    "\n",
    "val_data = coco_detection_yolo_format_val(\n",
    "    dataset_params={\n",
    "        'data_dir': config.DATA_DIR,\n",
    "        'images_dir': config.TRAIN_IMAGES_DIR,\n",
    "        'labels_dir': config.TRAIN_LABELS_DIR,\n",
    "        'classes': config.CLASSES\n",
    "    },\n",
    "    dataloader_params=config.DATALOADER_PARAMS\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
